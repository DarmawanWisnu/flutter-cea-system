{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# CEA System - Model Training\n",
                "\n",
                "This notebook trains the Random Forest model for the CEA system using data exported from your local environment.\n",
                "\n",
                "### Steps:\n",
                "1. Upload `dataset_pairs.csv`.\n",
                "2. Run all cells to train the model.\n",
                "3. Download the trained model files."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 1. Install Dependencies\n",
                "!pip install pandas numpy scikit-learn joblib"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 2. Upload Data\n",
                "from google.colab import files\n",
                "import os\n",
                "\n",
                "uploaded = files.upload()\n",
                "filename = next(iter(uploaded))\n",
                "print(f\"Uploaded: {filename}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 3. Preprocessing Logic (from services/ml/preprocessing.py)\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "import joblib\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.preprocessing import StandardScaler\n",
                "\n",
                "TELEMETRY_FEATURES = [\"ppm\", \"ph\", \"tempC\", \"humidity\", \"waterTemp\", \"waterLevel\"]\n",
                "TARGETS = [\"phUp\", \"phDown\", \"nutrientAdd\", \"refill\"]\n",
                "\n",
                "def prepare_xy(df):\n",
                "    # Ensure required columns exist\n",
                "    missing_cols = [c for c in TELEMETRY_FEATURES + TARGETS if c not in df.columns]\n",
                "    if missing_cols:\n",
                "        raise ValueError(f\"Missing columns in CSV: {missing_cols}\")\n",
                "\n",
                "    X = df[TELEMETRY_FEATURES].copy()\n",
                "    y = df[TARGETS].copy()\n",
                "    X = X.fillna(method=\"ffill\").fillna(0.0)\n",
                "    y = y.fillna(0)\n",
                "    return X, y\n",
                "\n",
                "def split_and_scale(X, y, test_size=0.2, random_state=42):\n",
                "    scaler = StandardScaler()\n",
                "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
                "    scaler.fit(X_train)\n",
                "    X_train_s = scaler.transform(X_train)\n",
                "    X_val_s = scaler.transform(X_val)\n",
                "    return X_train_s, X_val_s, y_train, y_val, scaler"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 4. Training Logic (from services/ml/trainer.py)\n",
                "import datetime\n",
                "import json\n",
                "from sklearn.ensemble import RandomForestRegressor\n",
                "from sklearn.multioutput import MultiOutputRegressor\n",
                "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
                "\n",
                "def train_model(csv_path):\n",
                "    print(\"Loading dataset...\")\n",
                "    df = pd.read_csv(csv_path)\n",
                "    \n",
                "    if df.empty:\n",
                "        raise RuntimeError(\"Dataset is empty.\")\n",
                "\n",
                "    X, y = prepare_xy(df)\n",
                "    X_train_s, X_val_s, y_train, y_val, scaler = split_and_scale(X, y)\n",
                "\n",
                "    print(\"Training RandomForest...\")\n",
                "    base = RandomForestRegressor(n_estimators=100, n_jobs=-1, random_state=42)\n",
                "    model = MultiOutputRegressor(base)\n",
                "    model.fit(X_train_s, y_train)\n",
                "\n",
                "    # Evaluation\n",
                "    y_pred = model.predict(X_val_s)\n",
                "    maes = mean_absolute_error(y_val, y_pred, multioutput='raw_values')\n",
                "    rmses = np.sqrt(mean_squared_error(y_val, y_pred, multioutput='raw_values'))\n",
                "\n",
                "    print(\"Training complete.\")\n",
                "    print(f\"MAE: {maes}\")\n",
                "    print(f\"RMSE: {rmses}\")\n",
                "    \n",
                "    return model, scaler, maes, rmses, list(X.columns), list(y.columns)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 5. Run Training\n",
                "model, scaler, maes, rmses, feature_names, target_names = train_model(filename)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 6. Save and Download Model\n",
                "ts = datetime.datetime.utcnow().strftime(\"%Y%m%dT%H%M%SZ\")\n",
                "version = \"v\" + ts\n",
                "output_dir = version\n",
                "os.makedirs(output_dir, exist_ok=True)\n",
                "\n",
                "joblib.dump(model, os.path.join(output_dir, \"model.pkl\"))\n",
                "joblib.dump(scaler, os.path.join(output_dir, \"scaler.pkl\"))\n",
                "\n",
                "metadata = {\n",
                "    \"version\": version,\n",
                "    \"timestamp\": ts,\n",
                "    \"mae\": maes.tolist(),\n",
                "    \"rmse\": rmses.tolist(),\n",
                "    \"features\": feature_names,\n",
                "    \"targets\": target_names,\n",
                "}\n",
                "with open(os.path.join(output_dir, \"metadata.json\"), \"w\") as f:\n",
                "    json.dump(metadata, f, indent=2)\n",
                "\n",
                "# Zip and download\n",
                "!zip -r {version}.zip {version}\n",
                "files.download(f\"{version}.zip\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}